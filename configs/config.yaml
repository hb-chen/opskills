server:
  http:
    addr: ":8080"
  grpc:
    addr: ":8081"

log:
  level: "INFO"
  path: "./log"
  debug: false

llm:
  provider: "openai"
  api_key: ""  # Set via OPENAI_API_KEY env var
  model: "gpt-4"
  url: ""  # Custom LLM service URL (e.g., http://localhost:8000/v1), empty for default OpenAI API

skills:
  dir: "./skills"

agent:
  # Checkpoint: conversation memory, state recovery, and rollback
  checkpoint:
    enabled: true
    store_type: "file"  # file, memory, redis, postgres
    path: "./data/checkpoints"
  
  # Tracing: execution observation and reporting
  tracing:
    enabled: true
    markdown:
      enabled: true
      output_dir: "./data/reports"
    log:
      level: "standard"  # minimal, standard, detailed

